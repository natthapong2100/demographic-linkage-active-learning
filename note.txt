These have 3 files that I submitted. They are quite similar to each other but they have some differences.


1. the code that use the corrupted data with thousands rows (3k version)

2. the code that use the cleaned data with 1.3 million rows

3. the experiment version that mainly focus on randomly select and cut the data down into particular percentage to do the experiment.
The train_percentage variable will do the experiment starting from 1% to 10%, to see the metrics perfomance (precision, recall, f1) for both CV steps and test prediction datasets.

